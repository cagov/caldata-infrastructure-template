name: docs
on:
  push:
    branches:
      - main
permissions:
  contents: write
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: 3.x
{% if use_dbt %}
{% if dbt_target == 'BigQuery' %}
      - id: auth
        name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          # To set this up you should create a GCP service account
          # with the "BigQuery Metadata Viewer", "BigQuery Job User", and
          # "BigQuery Data Viewer" roles. This will allow it to execute read-only
          # queries against your data warehouse, which is needed to generate the docs
          # Next, create a service account JSON file, and put it into a GitHub actions
          # secret under the name GOOGLE_CREDENTIALS.
{% raw %}
          credentials_json: ${{ secrets.GOOGLE_CREDENTIALS }}
{% endraw %}
          export_environment_variables: true
{% elif dbt_target == 'Snowflake' %}
{{ 0/0 }}  # Intentionally error until we implement Snowflake
{% endif %}
{% endif %}
      - uses: actions/cache@v2
        with:
          key: {% raw %}${{ github.ref }}
{% endraw %}
          path: .cache
      - name: Install dependencies
        run: |
          pip install mkdocs-material
{% if use_dbt %}
          pip install -r transform/requirements.txt
      - name: Build dbt docs
        env:
          DBT_PROFILES_DIR: transform/ci
        run: |
          dbt deps --project-dir=transform
          dbt docs generate --project-dir=transform
          cp -r transform/target docs/dbt_docs
{% endif %}
      - run: mkdocs gh-deploy --force
